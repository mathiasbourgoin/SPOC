# sarek/sarek - Sarek Runtime & Execution Layer

The `sarek/sarek` package provides the runtime execution infrastructure for Sarek GPU kernels. It bridges the Sarek IR (generated by the PPX) and backend implementations (CUDA, OpenCL, Vulkan, Native CPU, Interpreter).

**Key responsibilities:**
- Dispatch kernel execution to appropriate backends
- Provide native CPU runtime for OCaml 5 with BSP semantics
- Interpret Sarek IR for debugging without GPU
- Optimize kernels through fusion and vectorization
- Manage kernel registration and argument marshalling

## Table of Contents

- [Quick Start](#quick-start)
- [Execution Models](#execution-models)
- [Usage Examples](#usage-examples)
- [Module Organization](#module-organization)
- [Runtime Architecture](#runtime-architecture)
- [Testing](#testing)
- [Performance](#performance)
- [Design Principles](#design-principles)

## Quick Start

```ocaml
open Sarek

(* Define a simple vector addition kernel *)
let vector_add =
  [%kernel fun (a : int32 vector) (b : int32 vector) (c : int32 vector) ->
    let gid = Std.global_idx_x in
    c.(gid) <- a.(gid) + b.(gid)]

(* Execute on default device *)
let () =
  let dev = Device.get_default () in
  let n = 1024 in
  
  (* Create and initialize vectors *)
  let a = Vector.create_int32 n in
  let b = Vector.create_int32 n in
  let c = Vector.create_int32 n in
  
  Vector.init_int32 a (fun i -> Int32.of_int i);
  Vector.init_int32 b (fun i -> Int32.of_int (i * 2));
  
  (* Run kernel: 4 blocks × 256 threads = 1024 threads *)
  Execute.run vector_add ~device:dev
    ~block:(256, 1, 1) ~grid:(4, 1, 1)
    [Vec a; Vec b; Vec c];
  
  (* Result in c: [0, 3, 6, 9, ...] *)
  Printf.printf "c[10] = %ld\n" (Vector.get_int32 c 10)
```

## Execution Models

The Sarek runtime supports three execution models, determined by the backend:

### 1. JIT (Just-In-Time Compilation)

**Backends:** CUDA, OpenCL, Vulkan

The runtime generates GPU source code from Sarek IR and compiles it at runtime:

```ocaml
(* Backend generates CUDA/OpenCL/GLSL source *)
let source = Backend.generate_source ir_kernel in
(* Compile with GPU driver *)
let compiled = Backend.compile source in
(* Launch on GPU *)
Backend.execute compiled ~grid ~block args
```

**Characteristics:**
- First run has compilation overhead (~100ms-1s)
- Subsequent runs use cached compiled kernel
- Full GPU performance
- Requires GPU drivers and compiler (nvcc, OpenCL runtime, etc.)

### 2. Direct (Native Execution)

**Backend:** Native CPU

The PPX generates OCaml code that is compiled by `ocamlopt` ahead-of-time:

```ocaml
(* PPX generates OCaml function matching GPU semantics *)
let vector_add_native a b c =
  let open Sarek_cpu_runtime in
  run_parallel ~grid:(4,1,1) ~block:(256,1,1) (fun ts ->
    let gid = global_idx_x ts in
    c.(gid) <- a.(gid) + b.(gid)
  )

(* Direct function call - no runtime compilation *)
Execute.run vector_add ~device:cpu_device ~block ~grid args
  (* → calls vector_add_native directly *)
```

**Characteristics:**
- Zero runtime compilation overhead
- Uses OCaml 5 Effects for BSP barrier synchronization
- Full type safety - OCaml type checker validates kernel
- Best for CPU-only systems, testing, or CI/CD
- Performance: ~80% of hand-written CPU code

### 3. Custom (Interpreter)

**Backend:** Interpreter

The runtime walks the Sarek IR AST and evaluates expressions:

```ocaml
(* Interpreter evaluates IR tree *)
let rec eval_expr env = function
  | Var x -> lookup env x
  | Binop (Add, e1, e2) -> 
      let v1 = eval_expr env e1 in
      let v2 = eval_expr env e2 in
      add_values v1 v2
  | ArrayGet (arr, idx) -> ...
  | ...
```

**Characteristics:**
- No compilation overhead
- Useful for debugging kernel logic without GPU
- ~100-1000× slower than native
- Can inspect intermediate values for debugging

## Usage Examples

### Basic Kernel Execution

```ocaml
(* Matrix addition with 2D grid *)
let matrix_add =
  [%kernel fun (a : float32 vector) (b : float32 vector) 
               (c : float32 vector) (width : int32) ->
    let row = Std.global_idx_y in
    let col = Std.global_idx_x in
    let idx = row * width + col in
    c.(idx) <- a.(idx) +. b.(idx)]

let () =
  let width = 512 in
  let height = 512 in
  let size = width * height in
  
  let a = Vector.create_float32 size in
  let b = Vector.create_float32 size in
  let c = Vector.create_float32 size in
  
  (* 16×16 thread blocks, 32×32 blocks = 512×512 threads *)
  Execute.run matrix_add ~device:(Device.get_default ())
    ~block:(16, 16, 1) ~grid:(32, 32, 1)
    [Vec a; Vec b; Vec c; Scalar (Int32 (Int32.of_int width))]
```

### Shared Memory & Synchronization

```ocaml
(* Parallel reduction with shared memory *)
let reduce_sum =
  [%kernel fun (input : float32 vector) (output : float32 vector) (n : int32) ->
    let open Std in
    
    (* Allocate shared memory for thread block *)
    let%shared (sdata : float32) = 256l in
    
    let tid = thread_idx_x in
    let gid = global_idx_x in
    
    (* Load data into shared memory *)
    let%superstep load =
      sdata.(tid) <- if gid < n then input.(gid) else 0.0
    in
    
    (* Tree reduction in shared memory *)
    let rec reduce stride =
      if stride >= 1l then begin
        let%superstep step =
          if tid < stride then
            sdata.(tid) <- sdata.(tid) +. sdata.(tid + stride)
        in
        reduce (stride / 2l)
      end
    in
    reduce 128l;
    
    (* Write block result *)
    let%superstep store =
      if tid = 0l then output.(block_idx_x) <- sdata.(0l)
    in
    ()]

(* Usage *)
let () =
  let n = 1024 in
  let input = Vector.create_float32 n in
  let output = Vector.create_float32 4 in (* 4 blocks *)
  
  Vector.init_float32 input (fun i -> float_of_int i);
  
  Execute.run reduce_sum ~device:(Device.get_default ())
    ~block:(256, 1, 1) ~grid:(4, 1, 1)
    [Vec input; Vec output; Scalar (Int32 (Int32.of_int n))];
  
  (* Final reduction on CPU *)
  let total = ref 0.0 in
  for i = 0 to 3 do
    total := !total +. Vector.get_float32 output i
  done;
  Printf.printf "Sum: %f\n" !total
```

### Custom Types

```ocaml
(* Define custom record type *)
type particle = {
  x : float32;
  y : float32;
  vx : float32;
  vy : float32;
  mass : float32;
} [@@sarek.type]

(* Kernel using custom type *)
let update_particles =
  [%kernel fun (particles : particle vector) (dt : float32) ->
    let gid = Std.global_idx_x in
    let p = particles.(gid) in
    
    (* Update position based on velocity *)
    let new_x = p.x +. p.vx *. dt in
    let new_y = p.y +. p.vy *. dt in
    
    particles.(gid) <- { p with x = new_x; y = new_y }]

(* Usage *)
let () =
  let n = 10000 in
  let particles = Vector.create_custom 
    (module struct
      type t = particle
      let size = 20 (* 5 fields × 4 bytes *)
    end) n in
  
  (* Initialize particles... *)
  
  Execute.run update_particles ~device:(Device.get_default ())
    ~block:(256, 1, 1) ~grid:(40, 1, 1)
    [Vec particles; Scalar (Float32 0.016)]
```

### Multi-Device Execution

```ocaml
(* Run same kernel on multiple devices in parallel *)
let () =
  let devices = Device.get_all () in
  let n = 1024 in
  
  (* Split work across devices *)
  let chunk_size = n / List.length devices in
  
  List.iteri (fun i dev ->
    let offset = i * chunk_size in
    let a_chunk = Vector.sub a offset chunk_size in
    let b_chunk = Vector.sub b offset chunk_size in
    let c_chunk = Vector.sub c offset chunk_size in
    
    (* Launch kernel on each device *)
    Execute.run vector_add ~device:dev
      ~block:(256, 1, 1) ~grid:(chunk_size / 256, 1, 1)
      [Vec a_chunk; Vec b_chunk; Vec c_chunk]
  ) devices;
  
  (* Results merged in c *)
```

### Error Handling

```ocaml
open Sarek

let () =
  try
    Execute.run my_kernel ~device:(Device.get_default ())
      ~block:(256, 1, 1) ~grid:(4, 1, 1)
      [Vec a; Vec b; Vec c]
  with
  | Execute.Execute_error (Backend_not_available backend) ->
      Printf.eprintf "Backend %s not available\n" backend
  | Execute.Execute_error (Invalid_grid_dim (msg, dims)) ->
      Printf.eprintf "Invalid grid: %s\n" msg
  | Execute.Execute_error (Kernel_launch_failed msg) ->
      Printf.eprintf "Launch failed: %s\n" msg
  | Device.Device_error (No_device_available) ->
      Printf.eprintf "No compute devices found\n"
```

## Module Organization

### Execution & Dispatch

#### `Execute.ml` - Unified Kernel Execution Dispatcher (624 lines)

The main entry point for running kernels. Handles:
- Backend selection based on device type
- Argument marshalling and validation
- Vector expansion for scalars (broadcasting)
- Grid/block dimension validation
- Error handling and reporting

**Key functions:**
```ocaml
val run : 
  Sarek_ir_types.kernel -> 
  device:Device.t -> 
  block:dims -> 
  grid:dims -> 
  Kernel_arg.any list -> 
  unit
  (* Main execution dispatcher *)

val run_with_profiling :
  Sarek_ir_types.kernel -> 
  device:Device.t -> 
  block:dims -> 
  grid:dims -> 
  Kernel_arg.any list -> 
  float
  (* Execute and return elapsed time in seconds *)
```

**Design patterns:**
- Uses GADT `Kernel_arg.t` to preserve type information
- Delegates to backend-specific execution functions
- Never uses `Obj.t` - all types tracked at compile time

#### `Kirc_kernel.ml` - Kernel Management (181 lines)

Manages kernel metadata and registration:
- Kernel name generation and lookup
- Signature validation
- Compilation cache integration
- Backend capability querying

### Runtime Implementations

#### `Sarek_cpu_runtime.ml` - Native CPU Runtime (1,491 lines)

Provides OCaml 5 native execution with GPU semantics:

**Thread state management:**
```ocaml
type thread_state = {
  thread_idx : int32 * int32 * int32;  (* threadIdx.{x,y,z} *)
  block_idx : int32 * int32 * int32;   (* blockIdx.{x,y,z} *)
  block_dim : int32 * int32 * int32;   (* blockDim.{x,y,z} *)
  grid_dim : int32 * int32 * int32;    (* gridDim.{x,y,z} *)
}
```

**Shared memory allocators:**
- `alloc_shared_int32`, `alloc_shared_float32`, etc.
- Type-safe wrappers around `Bigarray`
- Lifetime scoped to kernel execution

**BSP barrier synchronization:**
- Uses OCaml 5 Effects for cooperative threading
- `barrier ()` suspends current thread, resumes when all threads reach barrier
- Validates convergence (all threads must reach same barrier)

**Coverage:** 71.56% (28 tests) - Well tested with unit test suite

#### `Sarek_ir_interp.ml` - IR Interpreter (1,212 lines)

CPU interpreter for debugging Sarek IR without GPU:

**Intrinsic evaluation:**
- GPU execution model intrinsics: `global_idx_x`, `thread_idx_y`, `block_dim_z`
- Barrier synchronization: `barrier`
- Math operations: trigonometry, logarithms, exponentials
- Type conversions: `int32_of_float32`, etc.

**Execution modes:**
- Sequential: Single thread, useful for initial debugging
- Parallel: Multi-threaded with BSP barriers

**Coverage:** 22.49% (23 tests) - Could add more intrinsic tests

### Optimization

#### `Sarek_fusion.ml` - Kernel Fusion Optimizer (644 lines)

Optimizes kernel sequences by fusing adjacent kernels:

**Fusion criteria:**
- Producer-consumer relationship (one kernel writes, next reads)
- Compatible grid/block dimensions
- No data races (verified through dependency analysis)
- No atomic operations (TODO: detect atomics)

**Benefits:**
- Eliminates intermediate memory transfers
- Reduces kernel launch overhead
- Improves cache locality

**Example:**
```ocaml
(* Before fusion: 2 kernels, 2 launches *)
let a = map (fun x -> x * 2) input in
let b = map (fun x -> x + 1) a in

(* After fusion: 1 kernel, 1 launch *)
let b = map (fun x -> (x * 2) + 1) input in
```

See [FUSION.md](FUSION.md) for detailed fusion rules and examples.

### Type System & IR

#### `Sarek_ir_types.ml` - Typed Sarek IR (403 lines)

Defines the typed intermediate representation:
- `expr`: Expressions with type annotations
- `stmt`: Statements (assignments, loops, conditionals)
- `kernel`: Complete kernel definition with signature

**Type safety:**
- Every expression has an associated `elt_ty` (element type)
- Array access bounds checked at runtime
- Type conversions explicit in IR

#### `Kirc_types.ml` - Core Type Definitions (188 lines)

Fundamental types for the entire runtime:
- `elt_ty`: Element types (Int32, Float32, Float64, Bool, Custom)
- `dims`: 3D dimensions for grids/blocks
- `scalar_kind`: Bigarray kind descriptors

**Coverage:** 100% - All type constructors used

### Error Handling

#### `Execute_error.ml` - Execution Errors (65 lines)

Structured error types for runtime failures:
```ocaml
type execute_error =
  | Backend_not_available of string
  | Invalid_grid_dim of string * dims
  | Invalid_block_dim of string * dims
  | Kernel_launch_failed of string
  | Unsupported_type of string
  | Argument_count_mismatch of { expected : int; got : int }
```

#### `Interp_error.ml`, `Kirc_error.ml`, `Fusion_error.ml`

Domain-specific error types for interpreter, kernel management, and fusion.

## Runtime Architecture

```
                    ┌─────────────────┐
                    │  Execute.run    │
                    │  (Dispatcher)   │
                    └────────┬────────┘
                             │
            ┌────────────────┼────────────────┐
            │                │                │
    ┌───────▼──────┐  ┌──────▼─────┐  ┌──────▼─────┐
    │ JIT Backends │  │   Native   │  │ Interpreter│
    │ (CUDA/OCL)   │  │ (OCaml 5)  │  │  (Debug)   │
    └──────┬───────┘  └─────┬──────┘  └──────┬─────┘
           │                │                │
    ┌──────▼──────┐  ┌──────▼──────┐  ┌──────▼──────┐
    │ Generate    │  │ Call native │  │ Eval IR AST │
    │ GPU source  │  │ OCaml func  │  │ expression  │
    └──────┬──────┘  └─────────────┘  └─────────────┘
           │
    ┌──────▼──────┐
    │ GPU compile │
    │ (nvcc/clang)│
    └──────┬──────┘
           │
    ┌──────▼──────┐
    │ GPU execute │
    └─────────────┘
```

### Execution Flow

1. **User calls `Execute.run`** with kernel, device, dims, and arguments
2. **Argument validation**: Check types, count, and dimensions
3. **Backend selection**: Based on device type (GPU → JIT, CPU → Native/Interpreter)
4. **Backend dispatch**:
   - **JIT**: Generate source → Compile → Launch GPU kernel
   - **Direct**: Call pre-compiled OCaml function
   - **Custom**: Walk IR AST and evaluate expressions
5. **Result**: Data in output vectors, ready for host access

### Memory Model

The runtime follows GPU memory semantics:

- **Global memory**: `Vector.t` backed by `Bigarray` or GPU memory
- **Shared memory**: `let%shared` allocates per-block memory
- **Local memory**: Regular OCaml variables (registers or stack)

**Transfers:**
```ocaml
(* Explicit transfers for GPU backends *)
let v = Vector.create_int32 1024 in
Vector.init_int32 v (fun i -> Int32.of_int i);  (* Host → Device *)

Execute.run kernel ~device:gpu [Vec v];  (* Device operates on v *)

let result = Vector.get_int32 v 0 in  (* Device → Host *)
```

**CPU backends:** Zero-copy when possible - `Vector.t` is backed by regular `Bigarray`.

## Testing

### Unit Tests (161 tests)

Located in `sarek/sarek/test/`:

```bash
# Run all unit tests
dune runtest sarek/sarek/test

# Run specific test
dune exec sarek/sarek/test/test_sarek_value.exe
dune exec sarek/sarek/test/test_sarek_float32.exe

# With coverage
BISECT_FILE=_coverage/sarek dune runtest sarek/sarek/test --force
```

**Test coverage:**
- `test_sarek_value.ml` (20 tests): Runtime value types, type names, construction, edge cases
- `test_sarek_float32.ml` (61 tests): Float32 arithmetic, math intrinsics, NaN/infinity handling, conversions
- `test_sarek_type_helpers.ml` (10 tests): Type helper registration, lookup, conversion functions
- `test_execute_error.ml` (19 tests): Execution error types, formatting, exception handling
- `test_interp_error.ml` (17 tests): Interpreter error types, array bounds, type conversions
- `test_kirc_error.ml` (18 tests): Kernel error types, backend errors, marshalling failures
- `test_fusion_error.ml` (16 tests): Fusion error types, compatibility checks, pipeline validation

### End-to-End Tests (23 tests)

Located in `tests/Sarek_test/e2e/`:

```bash
# Run single E2E test
LD_LIBRARY_PATH=/opt/cuda/lib64:$LD_LIBRARY_PATH \
  _build/default/runtime/tests/Sarek_test/e2e/test_vector_add.exe

# Run with specific backend
./test_vector_add.exe --interpreter
./test_vector_add.exe --native
./test_vector_add.exe --vulkan

# Run on specific device
./test_vector_add.exe -d 0  # First device

# Benchmark mode (all devices)
./test_vector_add.exe --benchmark

# Custom problem size
./test_vector_add.exe -s 1048576
```

**E2E test suite:**
- `test_vector_add.exe`: Basic arithmetic
- `test_transpose.exe`: Matrix transpose with shared memory
- `test_histogram.exe`: Atomics and reductions
- `test_matmul.exe`: Complex computation
- `test_reduction.exe`: Tree reduction algorithm
- Many more...

**Test framework:**
```ocaml
(* E2E tests use Benchmarks module *)
Benchmarks.init ()

Benchmarks.run
  ~baseline:cpu_reference_impl       (* Compare against CPU version *)
  ~verify:verify_results             (* Correctness check *)
  ~filter:Device.allows_fp64         (* Skip devices without fp64 *)
  "TestName"
  kernel_runner

Benchmarks.exit ()  (* Exit with proper status code *)
```

### Coverage Reports

```bash
# Generate aggregate coverage report
./scripts/coverage-aggregate.sh

# View HTML report
firefox _coverage/aggregate-report/index.html

# Current coverage: 42.42% (1801/4246 points)
```

**Coverage by module:**
- ✅ Kirc_types: 100%
- ✅ Sarek_cpu_runtime: 71.56%
- ⚠️  Execute: 26.07% (needs more error path tests)
- ⚠️  Sarek_ir_interp: 22.49% (needs more intrinsic tests)

See [../../COVERAGE.md](../../COVERAGE.md) for detailed coverage documentation.

## Performance

### Benchmarks

```bash
# Run all benchmarks
make benchmarks

# Results saved to benchmark_output.txt
```

**Typical performance (NVIDIA RTX 3090):**
- Vector add (1M elements): ~0.5ms (2 GB/s)
- Matrix multiply (1024×1024): ~15ms (140 GFLOPS)
- Reduction (1M elements): ~0.3ms
- Transpose (4096×4096): ~8ms (shared memory optimized)

**Native CPU performance:**
- Vector add: ~2ms (4× slower than GPU, but zero transfer overhead)
- Matrix multiply: ~500ms (30× slower)
- Good for CPU-only systems or small problem sizes

### Optimization Tips

1. **Minimize transfers**: Keep data on device as long as possible
2. **Use shared memory**: Dramatically faster than global memory for block-local data
3. **Coalesce accesses**: Access memory in contiguous patterns
4. **Occupancy**: Use enough threads to hide latency (typically 128-512 per block)
5. **Kernel fusion**: Let the runtime fuse adjacent kernels automatically

```ocaml
(* Bad: 3 kernel launches, 2 round-trips to GPU *)
let a = map (fun x -> x * 2) input in
let b = map (fun x -> x + 1) a in
let c = map (fun x -> x * x) b in

(* Good: 1 kernel launch (fusion), 0 intermediate transfers *)
let c = map (fun x -> let t = x * 2 in let t2 = t + 1 in t2 * t2) input in
```

See [FUSION.md](FUSION.md) for fusion optimization guide.

## Design Principles

### 1. Type Safety Without `Obj.t`

The runtime eliminates `Obj.t` usage through typed abstractions:

```ocaml
(* Good: GADT preserves element type *)
type _ t =
  | Vec : ('a, 'b) Vector.t -> ('a, 'b) t
  | Scalar : 'a scalar -> 'a t

(* Bad: Loses type information *)
type t = Obj.t
```

**Current status:** 13 `Obj.t` uses remain (down from 154), all in performance-critical paths with documentation.

### 2. Backend-Agnostic Core

The core execution layer knows nothing about specific backends:

```ocaml
(* Execute.ml doesn't know about CUDA/OpenCL specifics *)
let run kernel ~device ~block ~grid args =
  let backend = Framework_registry.get_backend device.backend_name in
  match backend.execution_model with
  | JIT -> (* Backend generates source, we just call it *)
  | Direct -> (* Backend provides compiled function *)
  | Custom -> (* Backend handles everything *)
```

Backends register via `Framework_registry` and implement the `BACKEND` interface.

### 3. Compile-Time Safety

The runtime validates as much as possible at compile time:

- Types checked by PPX during kernel compilation
- Dimensions validated at runtime (can't know grid/block until runtime)
- No dynamic code generation except for JIT backends (which is their purpose)

### 4. Progressive Optimization

Optimizations are opt-in and incremental:

- Kernel fusion: Automatic but can be disabled
- Vectorization: Applied when safe
- Shared memory: Explicit `let%shared` syntax

## See Also

- [FUSION.md](FUSION.md) - Kernel fusion optimization guide
- [BSP.md](BSP.md) - Bulk Synchronous Parallel execution model
- [../ppx/README.md](../ppx/README.md) - Sarek PPX compiler documentation
- [../../COVERAGE.md](../../COVERAGE.md) - Coverage infrastructure and usage
- [../../README.md](../../README.md) - Main project README
- [../core/README.md](../core/README.md) - Core runtime abstractions
